# pgEdge MCP Server

A Model Context Protocol (MCP) server written in Go that enables natural language queries against PostgreSQL databases. The server uses Claude AI to translate natural language questions into SQL queries by analyzing database metadata including table names, view names, column names, data types, and comments from pg_description.

> üöß WARNING
>
> This code was entirely generated by Claude Code. It has not been human reviewed and MUST NOT be put into production or released as stable code without a thorough review!

## Features

- **Natural Language to SQL**: Convert plain English questions into SQL queries using Claude AI
- **Comprehensive Schema Analysis**: Extracts and utilizes:
  - Table and view names
  - Column names and data types
  - Nullability constraints
  - Comments from pg_description (table and column descriptions)
  - Schema information
- **Multi-Database Support**: Query multiple PostgreSQL databases dynamically by specifying connection strings in queries
- **Configuration Management**: View and modify PostgreSQL server configuration parameters
- **MCP Protocol**: Implements the Model Context Protocol for stdio communication
- **Three MCP Tools**:
  - `query_database`: Execute natural language queries and get results
  - `get_schema_info`: Retrieve detailed database schema information
  - `set_pg_configuration`: Modify PostgreSQL server configuration parameters
- **MCP Resource**:
  - `pg://settings`: View all PostgreSQL configuration parameters with current and default values

## Documentation

For additional documentation, please see:

- **[Query Examples](docs/EXAMPLES.md)** - Comprehensive collection of example queries including basic data queries, schema discovery, multi-database queries, and advanced usage patterns
- **[Architecture Guide](docs/ARCHITECTURE.md)** - Detailed information about the project structure, components, data flow, and how to extend the server with new tools, resources, and prompts
- **[Troubleshooting Guide](docs/TROUBLESHOOTING.md)** - Comprehensive troubleshooting steps for common issues, connection problems, and debugging techniques

## Prerequisites

- Go 1.21 or higher
- PostgreSQL database (any version that supports pg_description)
- Anthropic API key (for Claude AI)

## Installation

### From Source

1. Clone the repository:
```bash
git clone <repository-url>
cd pgedge-mcp
```

2. Build the binary:
```bash
make build
# Or: go build -o bin/pgedge-mcp ./cmd/pgedge-mcp
```

3. The binary will be created as `bin/pgedge-mcp`.

## Configuration

### Environment Variables

The server requires the following environment variables:

- `POSTGRES_CONNECTION_STRING` (required): PostgreSQL connection string
  - Format: `postgres://username:password@host:port/database?sslmode=disable`
  - Example: `postgres://myuser:mypass@localhost:5432/mydb?sslmode=disable`

- `ANTHROPIC_API_KEY` (required for natural language queries): Your Anthropic API key
  - Get yours at: https://console.anthropic.com/

- `ANTHROPIC_MODEL` (optional): Claude model to use
  - Default: `claude-sonnet-4-5`
  - Other options: `claude-haiku-4-5`, `claude-opus-4-1`

### Configuration File for Claude Desktop

To use this MCP server with Claude Desktop, add it to your MCP configuration file:

**Location**:
- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`
- Windows: `%APPDATA%\Claude\claude_desktop_config.json`
- Linux: `~/.config/Claude/claude_desktop_config.json`

**Configuration**:
```json
{
  "mcpServers": {
    "pgedge": {
      "command": "/absolute/path/to/pgedge-mcp/bin/pgedge-mcp",
      "env": {
        "POSTGRES_CONNECTION_STRING": "postgres://username:password@localhost:5432/database_name?sslmode=disable",
        "ANTHROPIC_API_KEY": "sk-ant-your-api-key-here",
        "ANTHROPIC_MODEL": "claude-sonnet-4-5"
      }
    }
  }
}
```

Replace `/absolute/path/to/pgedge-mcp` with the full path to your project directory.

## Usage

### With Claude Desktop

1. Configure the server in your Claude Desktop config (see above)
2. Restart Claude Desktop
3. The server will automatically start when needed
4. Available tools will appear in Claude's interface:
   - `query_database`: Ask questions about your data
   - `get_schema_info`: View database schema

### Query Examples

Once configured, you can ask Claude natural language questions about your data:

**Basic Queries:**
- "Show me all customers who made purchases in the last month"
- "What are the top 10 products by revenue?"
- "List all users who haven't logged in for more than 30 days"

**Schema Discovery:**
- "Show me the database schema"
- "What tables are available?"
- "Describe the customers table"

**Multi-Database Queries:**
- "Show users at postgres://localhost:5433/other_db" (temporary connection)
- "Set default database to postgres://analytics-server/analytics" (change default)

For a comprehensive collection of examples including advanced queries, multi-database patterns, and real-world scenarios, see **[Query Examples](docs/EXAMPLES.md)**.

### Multi-Database Support

The server supports querying multiple PostgreSQL databases dynamically by including connection strings in your queries:

- **Temporary queries**: Include `at postgres://...` in your query to connect temporarily
- **Change default**: Use `set default database to postgres://...` to switch permanently
- **Connection format**: `postgres://[user[:password]@][host][:port][/dbname][?params]`

See the **[Query Examples](docs/EXAMPLES.md)** guide for detailed examples and patterns.

## How It Works

1. **Metadata Extraction**: On startup, the server connects to PostgreSQL and extracts:
   - All tables and views (excluding system schemas)
   - Column information (names, data types, nullability)
   - Comments from pg_description for both tables and columns

2. **Natural Language Processing**: When you ask a question:
   - The question and schema context are sent to Claude AI
   - Claude analyzes the schema and generates appropriate SQL
   - The generated SQL is executed against your database
   - Results are formatted and returned

3. **Schema Context**: The LLM receives rich context including:
   ```
   schema_name.table_name (TABLE/VIEW)
     Description: [from pg_description]
     Columns:
       - column_name (data_type) [NULL] - [column description]
       ...
   ```

## Adding Database Comments

To get the most value from this tool, add comments to your database objects:

```sql
-- Add table comment
COMMENT ON TABLE customers IS 'Customer information including contact details and preferences';

-- Add column comments
COMMENT ON COLUMN customers.created_at IS 'Timestamp when the customer account was created';
COMMENT ON COLUMN customers.last_login IS 'Last successful login timestamp';
COMMENT ON COLUMN customers.segment IS 'Customer segment: premium, standard, or basic';

-- Add view comment
COMMENT ON VIEW active_customers IS 'Customers who have logged in within the last 90 days';
```

These comments help Claude understand your data model and generate more accurate queries.

## Development

### Project Structure

```
pgedge-mcp/
‚îú‚îÄ‚îÄ cmd/pgedge-mcp/          # Application entry point
‚îú‚îÄ‚îÄ internal/                # Private packages
‚îÇ   ‚îú‚îÄ‚îÄ database/            # PostgreSQL integration
‚îÇ   ‚îú‚îÄ‚îÄ llm/                 # Claude API client
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                 # MCP protocol
‚îÇ   ‚îî‚îÄ‚îÄ tools/               # Tool implementations
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îú‚îÄ‚îÄ configs/                 # Configuration examples
‚îî‚îÄ‚îÄ bin/                     # Compiled binaries
```

For detailed architecture information, see [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md).

### Running Locally

For testing without an MCP client:

```bash
# Set environment variables
export POSTGRES_CONNECTION_STRING="postgres://localhost/mydb?sslmode=disable"
export ANTHROPIC_API_KEY="sk-ant-your-key"

# Run the server
./bin/pgedge-mcp
```

The server will read JSON-RPC messages from stdin and write responses to stdout.

### Running Tests

The project includes a comprehensive unit test suite covering all major components:

```bash
# Run all tests
go test ./...

# Run tests with verbose output
go test -v ./...

# Run tests with coverage report
go test -cover ./...

# Generate detailed coverage report
go test -coverprofile=coverage.out ./...
go tool cover -html=coverage.out
```

**Test Coverage:**
- `internal/database`: Parser functions, connection management
- `internal/llm`: LLM client with HTTP mocking
- `internal/tools`: Tool registry and helper functions
- `internal/resources`: Resource registry
- `test`: Integration tests for the compiled MCP server binary

The tests use mocking where appropriate to avoid requiring external dependencies (database connections, API keys) for unit tests.

### Regression/Integration Tests

The project includes integration tests that test the compiled MCP server binary end-to-end by communicating via the MCP protocol (JSON-RPC over stdio):

```bash
# Run integration tests
cd test && go test -v

# Set custom database connection for integration tests (optional)
TEST_POSTGRES_CONNECTION_STRING="postgres://localhost/testdb?sslmode=disable" \
  go test -v ./test

# Run with custom API key (optional)
TEST_ANTHROPIC_API_KEY="your-key" \
  go test -v ./test
```

**What the Integration Tests Cover:**
- MCP protocol initialize handshake
- tools/list - Listing all available tools
- resources/list - Listing all available resources
- resources/read - Reading the pg://settings resource
- tools/call - Calling the get_schema_info tool
- query_database - Natural language query "What is the PostgreSQL version?" (requires TEST_ANTHROPIC_API_KEY)
- JSON-RPC request/response format validation
- Server startup and graceful shutdown

The integration tests automatically build the binary if it doesn't exist and handle server lifecycle management. Tests include retry logic to account for asynchronous metadata loading.

**Note:** The `QueryPostgreSQLVersion` test requires a valid Anthropic API key set in the `TEST_ANTHROPIC_API_KEY` environment variable, as it tests the full end-to-end flow including LLM natural language to SQL conversion. If the API key is not provided, this test will be skipped. The test works with any PostgreSQL version (9.x, 10+, development versions, beta versions, etc.) without hardcoding version numbers.

### Testing with MCP Inspector

You can test the server using the MCP Inspector tool:

```bash
npx @modelcontextprotocol/inspector /path/to/bin/pgedge-mcp
```

## CI/CD

The project uses GitHub Actions for continuous integration and deployment. Workflows are triggered on pushes and pull requests to the `main` and `develop` branches.

### Workflows

#### Build Workflow (`.github/workflows/build.yml`)

- **Triggers**: Push and pull requests to main/develop branches
- **Go Versions**: Tests against Go 1.21, 1.22, and 1.23
- **Steps**:
  - Checkout code
  - Set up Go with caching
  - Verify dependencies
  - Build the binary
  - Upload build artifacts (from Go 1.23)

#### Test Workflow (`.github/workflows/test.yml`)

Includes multiple jobs:

**Unit Tests**
- Runs on Go 1.21, 1.22, and 1.23
- Executes all unit tests with race detection
- Generates code coverage reports (HTML and text)
- Uploads coverage artifacts for download

**Integration Tests**
- Runs on Go 1.23
- Tests against PostgreSQL versions 14, 15, 16, and 17
- Uses Docker containers for PostgreSQL services
- Runs with and without Anthropic API key (if configured)

**Lint**
- Uses golangci-lint for code quality checks
- Configuration in `.golangci.yml`

### Status Badges

Add these badges to track CI/CD status:

```markdown
![Build](https://github.com/YOUR_ORG/pgedge-mcp/workflows/Build/badge.svg)
![Tests](https://github.com/YOUR_ORG/pgedge-mcp/workflows/Tests/badge.svg)
```

### Secrets Configuration

To enable all CI/CD features, configure these GitHub repository secrets:

- `ANTHROPIC_API_KEY`: (Optional) For running integration tests with actual LLM queries

## MCP Protocol Implementation

This server implements the Model Context Protocol version `2024-11-05` with the following methods:

- `initialize`: Server initialization and capability negotiation
- `tools/list`: List available tools
- `tools/call`: Execute a tool

### Available Tools

#### query_database

Executes a natural language query against the PostgreSQL database. Supports dynamic connection strings to query different databases.

**Input Examples**:

Basic query:
```json
{
  "query": "Show me all users created in the last week"
}
```

Query with temporary connection:
```json
{
  "query": "Show me table list at postgres://localhost:5433/other_db"
}
```

Set new default connection:
```json
{
  "query": "Set default database to postgres://localhost/analytics"
}
```

**Output**:
```
Natural Language Query: Show me all users created in the last week

Generated SQL:
SELECT * FROM users WHERE created_at >= NOW() - INTERVAL '7 days' ORDER BY created_at DESC

Results (15 rows):
[
  {
    "id": 123,
    "username": "john_doe",
    "created_at": "2024-10-25T14:30:00Z",
    ...
  },
  ...
]
```

#### get_schema_info

Retrieves database schema information.

**Input** (optional):
```json
{
  "schema_name": "public"
}
```

**Output**:
```
Database Schema Information:
============================

public.users (TABLE)
  Description: User accounts and authentication
  Columns:
    - id: bigint
    - username: character varying(255)
      Description: Unique username for login
    - created_at: timestamp with time zone (nullable)
      Description: Account creation timestamp
    ...
```

#### set_pg_configuration

Sets PostgreSQL server configuration parameters using ALTER SYSTEM SET. Changes persist across server restarts. Some parameters require a restart to take effect.

**Input**:
```json
{
  "parameter": "max_connections",
  "value": "200"
}
```

Use "DEFAULT" as the value to reset to default:
```json
{
  "parameter": "work_mem",
  "value": "DEFAULT"
}
```

**Output**:
```
Configuration parameter 'max_connections' updated successfully.

Parameter: max_connections
Description: Sets the maximum number of concurrent connections
Type: integer
Context: postmaster

Previous value: 100
New value: 200

‚ö†Ô∏è  WARNING: This parameter requires a server restart to take effect.
The change has been saved to postgresql.auto.conf but will not be active until the server is restarted.

SQL executed: ALTER SYSTEM SET max_connections = '200'
```

### Available Resources

Resources provide read-only access to database information and configuration.

#### pg://settings

Returns PostgreSQL server configuration parameters including current values, default values, pending changes, and descriptions.

**Access**: Read the resource to view all PostgreSQL configuration settings from pg_settings.

**Output**: JSON array with detailed information about each configuration parameter:
```json
[
  {
    "name": "max_connections",
    "current_value": "100",
    "category": "Connections and Authentication / Connection Settings",
    "description": "Sets the maximum number of concurrent connections.",
    "context": "postmaster",
    "type": "integer",
    "source": "configuration file",
    "min_value": "1",
    "max_value": "262143",
    "default_value": "100",
    "reset_value": "100",
    "pending_restart": false
  },
  ...
]
```

## Security Considerations

1. **Database Credentials**: Store connection strings securely
   - Use environment variables
   - Never commit credentials to version control
   - Consider using password files or secret management systems

2. **API Keys**: Protect your Anthropic API key
   - Store in environment variables
   - Rotate keys regularly
   - Monitor API usage

3. **Query Safety**: The server executes generated SQL directly
   - Review the SQL before execution when possible
   - Use read-only database users when appropriate
   - Consider implementing query validation/sandboxing
   - Monitor for suspicious queries

4. **Configuration Management**: The `set_pg_configuration` tool modifies server settings
   - Requires PostgreSQL superuser privileges
   - Changes persist across server restarts via `postgresql.auto.conf`
   - Test configuration changes in development before applying to production
   - Some parameters require a server restart to take effect
   - Keep backups of configuration files before making changes

5. **Network Security**:
   - Use SSL/TLS for PostgreSQL connections when possible
   - Restrict database access to trusted networks

## Troubleshooting

**For detailed troubleshooting, see [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)**

### Quick Diagnostics

**Check logs:**
```bash
# macOS
tail -f ~/Library/Logs/Claude/mcp*.log

# Look for these messages:
# Database ready: X tables/views loaded
```

### Common Issues

**Server exits immediately:**
- Check `POSTGRES_CONNECTION_STRING` is correct
- Verify PostgreSQL is running
- See detailed solutions in [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)

**Tools not appearing:**
- Restart Claude Desktop completely
- Verify MCP config has absolute path to binary
- Check JSON syntax in config file

**Natural language queries fail:**
- Set `ANTHROPIC_API_KEY` in MCP config
- Verify API key is valid at https://console.anthropic.com/
- Check you have API credits

**Poor query results:**
- Add COMMENT statements to your database
- Be more specific in your questions
- Ask Claude to "show me the database schema" first

## License

[Add your license here]

## Contributing

[Add contribution guidelines here]

## Support

For issues, questions, or contributions, please [add contact/issue tracker information].
