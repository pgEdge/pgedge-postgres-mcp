# pgEdge Postgres MCP - Docker Compose Configuration
# Copy this file to .env and customize for your environment

# ============================================================================
# SERVICE PORTS
# ============================================================================
# Port for MCP server HTTP endpoint
MCP_SERVER_PORT=8080

# Port for web client
WEB_CLIENT_PORT=8081

# ============================================================================
# DATABASE CONNECTION
# ============================================================================
# PostgreSQL connection details
PGEDGE_DB_HOST=your-postgres-host
PGEDGE_DB_PORT=5432
PGEDGE_DB_NAME=your-database-name
PGEDGE_DB_USER=your-database-user
PGEDGE_DB_PASSWORD=your-database-password
PGEDGE_DB_SSLMODE=prefer

# ============================================================================
# EMBEDDING PROVIDER CONFIGURATION
# ============================================================================
# Provider for text embeddings: anthropic, openai, or ollama
PGEDGE_EMBEDDING_PROVIDER=anthropic

# Model to use for embeddings
# Anthropic: voyage-3, voyage-3-large (requires API key)
# OpenAI: text-embedding-3-small, text-embedding-3-large (requires API key)
# Ollama: nomic-embed-text, mxbai-embed-large (requires local Ollama)
PGEDGE_EMBEDDING_MODEL=voyage-3

# ============================================================================
# LLM API KEYS
# ============================================================================
# Anthropic API key (for Claude models and Voyage embeddings)
# Get your key from: https://console.anthropic.com/
PGEDGE_ANTHROPIC_API_KEY=your-anthropic-api-key-here

# OpenAI API key (for GPT models and OpenAI embeddings)
# Get your key from: https://platform.openai.com/
PGEDGE_OPENAI_API_KEY=your-openai-api-key-here

# Ollama server URL (for local models)
# Default: http://localhost:11434 (change if Ollama runs elsewhere)
PGEDGE_OLLAMA_URL=http://localhost:11434

# ============================================================================
# AUTHENTICATION CONFIGURATION
# ============================================================================
# The server supports both token-based and user-based authentication
# simultaneously. You can initialize both types during container startup.

# Initialize tokens (comma-separated list)
# Use for service-to-service authentication or API access
# Format: token1,token2,token3
# Example: INIT_TOKENS=my-secret-token-1,my-secret-token-2
INIT_TOKENS=

# Initialize users (comma-separated list of username:password pairs)
# Use for interactive user authentication with session tokens
# Format: username1:password1,username2:password2
# Example: INIT_USERS=alice:secret123,bob:secret456
INIT_USERS=

# Client token for CLI access (if using token authentication)
# This should match one of the tokens in INIT_TOKENS
MCP_CLIENT_TOKEN=

# ============================================================================
# LLM CONFIGURATION FOR CLIENTS
# ============================================================================
# Default LLM provider for chat clients: anthropic, openai, or ollama
PGEDGE_LLM_PROVIDER=anthropic

# Default LLM model for chat clients
# Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514, etc.
# OpenAI: gpt-5-main, gpt-4o, gpt-4-turbo, etc.
# Ollama: llama3, mistral, etc.
PGEDGE_LLM_MODEL=claude-sonnet-4-20250514

# ============================================================================
# DEBUGGING AND LOGGING
# ============================================================================
# Enable debug mode for server
PGEDGE_DEBUG=false

# Database operation logging: none, info, debug, trace
PGEDGE_DB_LOG_LEVEL=none

# LLM/Embedding operation logging: none, info, debug, trace
PGEDGE_LLM_LOG_LEVEL=none

# Disable colored output for CLI client
NO_COLOR=

# ============================================================================
# EXAMPLE CONFIGURATIONS
# ============================================================================

# Example 1: Stdio mode with Anthropic (development)
# Not applicable for Docker - Docker uses HTTP mode

# Example 2: HTTP mode with Anthropic Claude (production)
# MCP_SERVER_PORT=8080
# WEB_CLIENT_PORT=8081
# PGEDGE_DB_HOST=postgres.example.com
# PGEDGE_DB_PORT=5432
# PGEDGE_DB_NAME=myapp
# PGEDGE_DB_USER=postgres
# PGEDGE_DB_PASSWORD=secure_password
# PGEDGE_EMBEDDING_PROVIDER=anthropic
# PGEDGE_EMBEDDING_MODEL=voyage-3
# PGEDGE_ANTHROPIC_API_KEY=sk-ant-api03-...
# INIT_TOKENS=production-token-1,production-token-2
# PGEDGE_LLM_PROVIDER=anthropic
# PGEDGE_LLM_MODEL=claude-sonnet-4-20250514

# Example 3: With OpenAI
# PGEDGE_EMBEDDING_PROVIDER=openai
# PGEDGE_EMBEDDING_MODEL=text-embedding-3-small
# PGEDGE_OPENAI_API_KEY=sk-proj-...
# PGEDGE_LLM_PROVIDER=openai
# PGEDGE_LLM_MODEL=gpt-4o

# Example 4: With local Ollama
# PGEDGE_EMBEDDING_PROVIDER=ollama
# PGEDGE_EMBEDDING_MODEL=nomic-embed-text
# PGEDGE_OLLAMA_URL=http://host.docker.internal:11434
# PGEDGE_LLM_PROVIDER=ollama
# PGEDGE_LLM_MODEL=llama3

# Example 5: With user authentication
# INIT_USERS=alice:password123,bob:password456

# Example 6: With both tokens and users
# INIT_TOKENS=api-token-1,api-token-2
# INIT_USERS=alice:password123,bob:password456
